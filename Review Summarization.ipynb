{"cells": [{"cell_type": "code", "execution_count": 2, "id": "37c8a4e6-d87c-4b4f-b3c7-99bfdef9c191", "metadata": {}, "outputs": [], "source": "import pyspark.sql.functions as F"}, {"cell_type": "code", "execution_count": 2, "id": "1609250a-a936-40f5-b5a7-430dc8934115", "metadata": {"tags": []}, "outputs": [], "source": "spark = SparkSession.builder.appName(\"SparkNLP\").config(\"spark.driver.memory\", \"5g\").getOrCreate()"}, {"cell_type": "code", "execution_count": 24, "id": "9449333c-2f62-490d-997b-0cb76286246e", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "metadata_df = spark.read.json('gs://msca-bdp-project-goodreads/goodreads_books.json')\ninteractions_df = spark.read.option(\"header\", \"true\").csv('gs://msca-bdp-project-goodreads/goodreads_interactions.csv')"}, {"cell_type": "code", "execution_count": 3, "id": "e98c0ff8-6664-415f-be03-5598983a4a7a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "-RECORD 0----------\n user_id     | 0   \n book_id     | 948 \n is_read     | 1   \n rating      | 5   \n is_reviewed | 0   \nonly showing top 1 row\n\n"}], "source": "interactions_df.show(1,vertical=True)"}, {"cell_type": "code", "execution_count": 4, "id": "71c1243d-081a-414c-95b0-b379ff4176f7", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "-RECORD 0----------\n user_id     | 0   \n book_id     | 913 \n is_read     | 0   \n rating      | 0   \n is_reviewed | 1   \n-RECORD 1----------\n user_id     | 0   \n book_id     | 911 \n is_read     | 0   \n rating      | 0   \n is_reviewed | 0   \n-RECORD 2----------\n user_id     | 0   \n book_id     | 910 \n is_read     | 0   \n rating      | 0   \n is_reviewed | 1   \n-RECORD 3----------\n user_id     | 0   \n book_id     | 907 \n is_read     | 0   \n rating      | 0   \n is_reviewed | 0   \n-RECORD 4----------\n user_id     | 0   \n book_id     | 906 \n is_read     | 0   \n rating      | 0   \n is_reviewed | 0   \nonly showing top 5 rows\n\n"}], "source": "interactions_df.filter(F.col('is_read')==0).show(5,vertical=True)"}, {"cell_type": "code", "execution_count": 7, "id": "ecbd3a82-48f9-40e4-aaea-d809c5ffc482", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "228648342"}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": "interactions_df.count()"}, {"cell_type": "code", "execution_count": 8, "id": "1c0482e4-7d32-4cd1-b2f6-ae9f42da4a15", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- user_id: string (nullable = true)\n |-- book_id: string (nullable = true)\n |-- is_read: string (nullable = true)\n |-- rating: string (nullable = true)\n |-- is_reviewed: string (nullable = true)\n\n"}], "source": "interactions_df.printSchema()"}, {"cell_type": "code", "execution_count": 9, "id": "b3ec1ff0-2ae0-4512-a299-81e4bf260733", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 10:====================================================>   (31 + 2) / 33]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+-------+-------+------+-----------+\n|user_id|book_id|is_read|rating|is_reviewed|\n+-------+-------+-------+------+-----------+\n|      0|      0|      0|     0|          0|\n+-------+-------+-------+------+-----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "interactions_df.selectExpr(*[\"sum(case when {} is null then 1 else 0 end) as {}\".format(c, c) for c in interactions_df.columns]).show()"}, {"cell_type": "code", "execution_count": 10, "id": "3e175439-6531-4c66-83b4-d361417d083a", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "(876145, 2360650)"}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": "interactions_df.select(F.col('user_id')).distinct().count(),interactions_df.select(F.col('book_id')).distinct().count()"}, {"cell_type": "code", "execution_count": 11, "id": "eb97bb92-5274-4ac5-b776-c9077823545a", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+------+\n|rating|\n+------+\n|     3|\n|     0|\n|     5|\n|     1|\n|     4|\n|     2|\n+------+\n\n"}], "source": "interactions_df.select(F.col('rating')).distinct().show()"}, {"cell_type": "code", "execution_count": 18, "id": "444c881e-a406-4f2e-9d47-da537a3637c9", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 67:========================================>               (24 + 8) / 33]\r"}, {"ename": "KeyboardInterrupt", "evalue": "", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)", "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minteractions_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_read\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistinct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, interactions_df\u001b[38;5;241m.\u001b[39mselect(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_reviewed\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mdistinct()\u001b[38;5;241m.\u001b[39mshow()\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py:484\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;124;03m name | Bob\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mshowString(n, \u001b[38;5;28mint\u001b[39m(truncate), vertical))\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1303\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1296\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1305\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1033\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1033\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1200\u001b[0m, in \u001b[0;36mGatewayConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while sending\u001b[39m\u001b[38;5;124m\"\u001b[39m, e, proto\u001b[38;5;241m.\u001b[39mERROR_ON_SEND)\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1200\u001b[0m     answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   1201\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m answer\u001b[38;5;241m.\u001b[39mstartswith(proto\u001b[38;5;241m.\u001b[39mRETURN_MESSAGE):\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n", "\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}], "source": "interactions_df.select(F.col('is_read')).distinct().show(), interactions_df.select(F.col('is_reviewed')).distinct().show()"}, {"cell_type": "code", "execution_count": 14, "id": "88f65240-0ed7-4942-a342-c5204c96ef17", "metadata": {}, "outputs": [], "source": "user_books = interactions_df.filter(F.col('is_read')==1).groupBy(\"user_id\").agg(F.collect_set(\"book_id\").alias(\"books_read\"))"}, {"cell_type": "code", "execution_count": 15, "id": "37d50c26-1a63-4199-9c0d-5452e9b62969", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "836433"}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": "user_books.count()"}, {"cell_type": "code", "execution_count": 20, "id": "0bc69d8c-89bb-488d-b6aa-6e1b5e1178da", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 53:======================================================> (32 + 1) / 33]\r"}, {"name": "stdout", "output_type": "stream", "text": "-RECORD 0--------------------------\n user_id    | 100010               \n books_read | [41585, 13098, 10... \n-RECORD 1--------------------------\n user_id    | 100090               \n books_read | [129074, 339574, ... \n-RECORD 2--------------------------\n user_id    | 100129               \n books_read | [1022252, 1047, 9... \n-RECORD 3--------------------------\n user_id    | 100140               \n books_read | [93854, 1012, 134... \n-RECORD 4--------------------------\n user_id    | 100156               \n books_read | [50675, 22143, 50... \nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "user_books.show(5,vertical=True)"}, {"cell_type": "code", "execution_count": null, "id": "9ad48c71-726d-4186-b10a-c1d4d03d2276", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "7dda1381-97c8-4044-b262-7124fb0ae9a6", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "d5bc2b5d-0cde-457d-96c8-08868ae722e6", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "markdown", "id": "fa49a0b5-604d-461f-9b0f-1da8f86abff3", "metadata": {}, "source": "## CONTENT BASED FILTERING"}, {"cell_type": "code", "execution_count": 3, "id": "3e10d1bf-6cb9-41fb-92aa-6f33178d83af", "metadata": {}, "outputs": [{"ename": "NameError", "evalue": "name 'metadata_df' is not defined", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmetadata_df\u001b[49m\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m1\u001b[39m,vertical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n", "\u001b[0;31mNameError\u001b[0m: name 'metadata_df' is not defined"]}], "source": "metadata_df.show(1,vertical=True)"}, {"cell_type": "code", "execution_count": 25, "id": "816849a3-ef7a-4aa3-9faf-4738c7f24d7b", "metadata": {}, "outputs": [], "source": "metadata_df = metadata_df.withColumn('average_rating',F.col('average_rating').cast('float'))\nmetadata_df = metadata_df.withColumn('ratings_count',F.col('ratings_count').cast('float'))"}, {"cell_type": "code", "execution_count": 26, "id": "0d4e5277-db5a-4836-bc05-56b99289705c", "metadata": {}, "outputs": [], "source": "metadata_df = metadata_df.withColumn('weighted_rating',F.col('average_rating')*F.col('ratings_count'))"}, {"cell_type": "code", "execution_count": 27, "id": "03b11c94-6941-458e-ba5f-b4ca7bb41c94", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 14:====================================================>   (65 + 4) / 69]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------------------------------------------------------+-------------+--------------+---------------+\n|title                                                      |ratings_count|average_rating|weighted_rating|\n+-----------------------------------------------------------+-------------+--------------+---------------+\n|The Hunger Games (The Hunger Games, #1)                    |4899965.0    |4.34          |2.1265848E7    |\n|Harry Potter and the Sorcerer's Stone (Harry Potter, #1)   |4765497.0    |4.45          |2.120646E7     |\n|Twilight (Twilight, #1)                                    |3941381.0    |3.57          |1.407073E7     |\n|To Kill a Mockingbird                                      |3255518.0    |4.26          |1.3868507E7    |\n|The Great Gatsby                                           |2758812.0    |3.89          |1.0731779E7    |\n|The Fault in Our Stars                                     |2429317.0    |4.26          |1.0348891E7    |\n|The Hobbit                                                 |2099680.0    |4.25          |8923640.0      |\n|Pride and Prejudice                                        |2078406.0    |4.25          |8833226.0      |\n|Harry Potter and the Prisoner of Azkaban (Harry Potter, #3)|1876252.0    |4.53          |8499422.0      |\n|1984                                                       |2023937.0    |4.14          |8379099.0      |\n+-----------------------------------------------------------+-------------+--------------+---------------+\nonly showing top 10 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "metadata_df.select('title','ratings_count','average_rating','weighted_rating').orderBy(F.col('weighted_rating').desc()).show(10,truncate=False)"}, {"cell_type": "code", "execution_count": null, "id": "75764901-58a0-4245-ad58-7588a76a6d73", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "4c9feaaf-ec2f-41b7-a1c6-58b48d4b36b3", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "markdown", "id": "92de3eb4-142e-45e4-b7a3-89fb9999e6d5", "metadata": {}, "source": "### reviews based recommendation"}, {"cell_type": "code", "execution_count": 2, "id": "9d0c7d66-f1bd-45a5-864a-a6b7b2fb7265", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Name: spark-nlp\nVersion: 4.4.0\nSummary: John Snow Labs Spark NLP is a natural language processing library built on top of Apache Spark ML. It provides simple, performant & accurate NLP annotations for machine learning pipelines, that scale easily in a distributed environment.\nHome-page: https://github.com/JohnSnowLabs/spark-nlp\nAuthor: John Snow Labs\nAuthor-email: \nLicense: \nLocation: /opt/conda/miniconda3/lib/python3.8/site-packages\nRequires: \nRequired-by: spark-nlp-display\n"}], "source": "!pip show spark-nlp"}, {"cell_type": "code", "execution_count": 4, "id": "6439cd47-b5b0-472c-895a-a86ca21421c4", "metadata": {"tags": []}, "outputs": [], "source": "import sparknlp\nfrom sparknlp.base import *\nfrom sparknlp.annotator import *\nfrom pyspark.ml.feature import *\n#from sparknlp.pretrained import PretrainedPipeline"}, {"cell_type": "code", "execution_count": 5, "id": "293f4b46-2272-4277-bc0d-b1ccba38e158", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "reviews_df = spark.read.json(\"gs://msca-bdp-project-goodreads/goodreads_reviews_dedup.json\")"}, {"cell_type": "code", "execution_count": 34, "id": "41740b3b-f792-443d-8b61-7475e0256c6f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "15739967"}, "execution_count": 34, "metadata": {}, "output_type": "execute_result"}], "source": "reviews_df.count()"}, {"cell_type": "code", "execution_count": 36, "id": "b80f6579-6797-4b41-a3a1-fe1ba6257343", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "-RECORD 0----------------------------\n book_id      | 24375664             \n date_added   | Fri Aug 25 13:55:... \n date_updated | Mon Oct 09 08:55:... \n n_comments   | 0                    \n n_votes      | 16                   \n rating       | 5                    \n read_at      | Sat Oct 07 00:00:... \n review_id    | 5cd416f3efc3f944f... \n review_text  | Mind blowingly co... \n started_at   | Sat Aug 26 00:00:... \n user_id      | 8842281e1d1347389... \nonly showing top 1 row\n\n"}], "source": "reviews_df.show(1,vertical=True)"}, {"cell_type": "code", "execution_count": 4, "id": "0e1200ab-50da-43ca-b45e-7b26c61f1c3f", "metadata": {}, "outputs": [], "source": "concatenated_reviews = reviews_df.groupby('book_id').agg(F.concat_ws(\" \", F.collect_list(\"review_text\")).alias(\"concatenated_reviews\"))"}, {"cell_type": "code", "execution_count": 5, "id": "8054533f-33ff-48d9-a4a5-6d1a716ac1da", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "concatenated_reviews.write.option('index',False).parquet('gs://msca-bdp-project-goodreads/concatenated_reviews/')"}, {"cell_type": "code", "execution_count": 4, "id": "aee4c5b5-bf30-46cb-b6ef-99d54c4298f4", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "concatenated_reviews = spark.read.parquet(\"gs://msca-bdp-project-goodreads/concatenated_reviews/\").limit(100)"}, {"cell_type": "code", "execution_count": 5, "id": "eccc6efe-cdaf-44ed-91a9-16b6c427ef5b", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "concatenated_reviews.write.mode('overwrite').option('index',False).parquet('gs://msca-bdp-project-goodreads/concatenated_reviews_limited/')"}, {"cell_type": "code", "execution_count": 6, "id": "e6bd2552-539c-4914-b2c3-98b9a86e0a78", "metadata": {"tags": []}, "outputs": [], "source": "concatenated_reviews = spark.read.parquet(\"gs://msca-bdp-project-goodreads/concatenated_reviews_limited/\")"}, {"cell_type": "code", "execution_count": 13, "id": "d4133b32-c086-40b8-8216-5f0c4c07c652", "metadata": {}, "outputs": [], "source": "del reviews_df"}, {"cell_type": "code", "execution_count": 7, "id": "56255ac4-1987-4883-8f3a-8298b1741ac9", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 5:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------+--------------------+\n| book_id|concatenated_reviews|\n+--------+--------------------+\n|10000053|Well, it was a da...|\n+--------+--------------------+\nonly showing top 1 row\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "concatenated_reviews.show(1)"}, {"cell_type": "code", "execution_count": 7, "id": "3b6b48c0-cc37-408c-87a6-65b66e534ff3", "metadata": {"tags": []}, "outputs": [], "source": "#bart = BartTransformer.load(\"gs://msca-bdp-project-goodreads/BART-LARGE-CNN/\").setTask(\"summarize:\").setMaxOutputLength(500).setInputCols([\"concatenated_reviews\"]).setOutputCol(\"summary_final\")"}, {"cell_type": "markdown", "id": "24de866d-28b5-447b-9fad-5e96b9b6f494", "metadata": {}, "source": "### review summarization"}, {"cell_type": "code", "execution_count": 6, "id": "3e1fc7d7-e361-46fc-a1eb-9e1354060214", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "t5_small download started this may take some time.\nApproximate size to download 241.9 MB\n[ | ]t5_small download started this may take some time.\nApproximate size to download 241.9 MB\nDownload done! Loading the resource.\n[ / ]"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "[ / ]"}, {"name": "stderr", "output_type": "stream", "text": "2023-11-17 02:12:20.914346: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-11-17 02:12:21.101449: W external/org_tensorflow/tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 65798144 exceeds 10% of free system memory.\n2023-11-17 02:12:21.303382: W external/org_tensorflow/tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 65798144 exceeds 10% of free system memory.\n2023-11-17 02:12:21.816871: W external/org_tensorflow/tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 65798144 exceeds 10% of free system memory.\n2023-11-17 02:12:21.866890: W external/org_tensorflow/tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 65798144 exceeds 10% of free system memory.\n"}, {"name": "stdout", "output_type": "stream", "text": "[ \u2014 ]"}, {"name": "stderr", "output_type": "stream", "text": "2023-11-17 02:12:22.236683: W external/org_tensorflow/tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 65798144 exceeds 10% of free system memory.\n"}, {"name": "stdout", "output_type": "stream", "text": "[OK!]\n"}], "source": "document_assembler = DocumentAssembler().setInputCol(\"concatenated_reviews\").setOutputCol(\"documents\")\n\nt5 = T5Transformer().pretrained(\"t5_small\").setTask(\"summarize:\").setMaxOutputLength(50).setInputCols([\"documents\"]).setOutputCol(\"summaries\")\n\nfinisher = Finisher().setInputCols([\"summaries\"]).setOutputCols([\"human_readable_summaries\"]).setOutputAsArray(False)\n\npipeline = Pipeline().setStages([document_assembler, t5, finisher])"}, {"cell_type": "code", "execution_count": 8, "id": "4cfae25e-44df-492e-b96f-0f7bcc0cca8d", "metadata": {"tags": []}, "outputs": [], "source": "results = pipeline.fit(concatenated_reviews).transform(concatenated_reviews)"}, {"cell_type": "code", "execution_count": 9, "id": "91e79887-cb32-456c-9847-a4363de88f63", "metadata": {}, "outputs": [], "source": "#del document_assembler,t5,finisher,pipeline"}, {"cell_type": "code", "execution_count": 10, "id": "77e1a201-c009-45e8-9c50-a21aa953720e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- book_id: string (nullable = true)\n |-- concatenated_reviews: string (nullable = true)\n |-- human_readable_summaries: string (nullable = true)\n\n"}], "source": "results.printSchema()"}, {"cell_type": "code", "execution_count": 11, "id": "be29345a-41b8-42f5-9422-c30d39b67b1b", "metadata": {"tags": []}, "outputs": [], "source": "results_new = results.select('book_id','human_readable_summaries')"}, {"cell_type": "code", "execution_count": 12, "id": "5e6f28f4-642e-44ea-84a1-d4d4f3ca5f00", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- book_id: string (nullable = true)\n |-- human_readable_summaries: string (nullable = true)\n\n"}], "source": "results_new.printSchema()"}, {"cell_type": "code", "execution_count": 11, "id": "87affc40-f86c-4153-82bf-392724d46785", "metadata": {}, "outputs": [{"data": {"text/plain": "2"}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": "results_new.rdd.getNumPartitions()"}, {"cell_type": "code", "execution_count": 12, "id": "259cd0b3-26e2-4ffa-810a-2a47fdb13e54", "metadata": {}, "outputs": [], "source": "results_new = results_new.repartition(20)"}, {"cell_type": "code", "execution_count": 14, "id": "2b01d6e8-1113-432e-9115-14f2b3c71305", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 7:>                  (0 + 1) / 1][Stage 8:>                  (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "-RECORD 0-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n book_id                  | 10000053                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n concatenated_reviews     | Well, it was a dark and story night (and couple of days) when I read this novel, and I'm sure that made my reading experience all the more fun, because, let's face it, Old Saint Paul's, while enjoyable to read, is not great literature. It is, rather, a delightful, rollicking melodrama that keeps on going, gets wobbly, and then rights itself, and never ever lets you catch your breath. \n I could not help but visualize this novel, set as a play, and performed, lit by gas, in a Victorian theatre. We have villains aplenty, including an appearance by the dastardly Earl of Rochester, beautiful but helpless heroines and gallant young men and suitors for the women. \n The novel is set during the horrors of the great plague of 1665, and so there are plenty of gory scenes of gruesome death, midnight visits by creepy undertakers and bizarre, but historically accurate methods of the ways the populace confronted and dealt with the plague. If you seek the rich creation of atmosphere and suspense that is offered by Dickens, forget it; if you want to experience the power that Fate has over people as found in Hardy you will be disappointed, but if you simply want a respite from the well-known classic Victorian authors and crave a simple, fun read to experience melodrama and adventure that never quits, read Ainsworth. It will be well worth your while and, I bet, will put a smile on your face. \n human_readable_summaries | the novel is set during the horrors of the great plague of 1665 . it is set as a play, and performed, lit by gas, in a Victorian theatre .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \nonly showing top 1 row\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 7:>                                                          (0 + 1) / 1]\r"}], "source": "results.show(1,vertical=True,truncate=False)"}, {"cell_type": "code", "execution_count": 1, "id": "230e6661-9d33-48e3-aa73-f565a64dcfa6", "metadata": {}, "outputs": [{"ename": "NameError", "evalue": "name 'results_new' is not defined", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults_new\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n", "\u001b[0;31mNameError\u001b[0m: name 'results_new' is not defined"]}], "source": "results_new.describe()"}, {"cell_type": "code", "execution_count": 13, "id": "648fdadf-2eaf-4ec8-b414-f70e9c797cc1", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/11/17 01:30:48 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1700181149142_0004_01_000003 on host: hub-msca-bdp-dphub-students-test2-johnk-dheeraj-w-0.c.msca-bdp-student-ap.internal. Exit status: 137. Diagnostics: [2023-11-17 01:30:47.960]Container killed on request. Exit code is 137\n[2023-11-17 01:30:47.961]Container exited with a non-zero exit code 137. \n[2023-11-17 01:30:47.962]Killed by external signal\n.\n23/11/17 01:30:48 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 3 for reason Container from a bad node: container_1700181149142_0004_01_000003 on host: hub-msca-bdp-dphub-students-test2-johnk-dheeraj-w-0.c.msca-bdp-student-ap.internal. Exit status: 137. Diagnostics: [2023-11-17 01:30:47.960]Container killed on request. Exit code is 137\n[2023-11-17 01:30:47.961]Container exited with a non-zero exit code 137. \n[2023-11-17 01:30:47.962]Killed by external signal\n.\n23/11/17 01:30:48 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 3 on hub-msca-bdp-dphub-students-test2-johnk-dheeraj-w-0.c.msca-bdp-student-ap.internal: Container from a bad node: container_1700181149142_0004_01_000003 on host: hub-msca-bdp-dphub-students-test2-johnk-dheeraj-w-0.c.msca-bdp-student-ap.internal. Exit status: 137. Diagnostics: [2023-11-17 01:30:47.960]Container killed on request. Exit code is 137\n[2023-11-17 01:30:47.961]Container exited with a non-zero exit code 137. \n[2023-11-17 01:30:47.962]Killed by external signal\n.\n23/11/17 01:30:48 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 7.0 (TID 78) (hub-msca-bdp-dphub-students-test2-johnk-dheeraj-w-0.c.msca-bdp-student-ap.internal executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container from a bad node: container_1700181149142_0004_01_000003 on host: hub-msca-bdp-dphub-students-test2-johnk-dheeraj-w-0.c.msca-bdp-student-ap.internal. Exit status: 137. Diagnostics: [2023-11-17 01:30:47.960]Container killed on request. Exit code is 137\n[2023-11-17 01:30:47.961]Container exited with a non-zero exit code 137. \n[2023-11-17 01:30:47.962]Killed by external signal\n.\n[Stage 7:>                                                          (0 + 1) / 1]\r"}, {"ename": "KeyboardInterrupt", "evalue": "", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)", "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py:664\u001b[0m, in \u001b[0;36mDataFrame.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    655\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the number of rows in this :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \n\u001b[1;32m    657\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;124;03m    2\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1303\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1296\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1305\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1033\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1033\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1200\u001b[0m, in \u001b[0;36mGatewayConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while sending\u001b[39m\u001b[38;5;124m\"\u001b[39m, e, proto\u001b[38;5;241m.\u001b[39mERROR_ON_SEND)\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1200\u001b[0m     answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   1201\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m answer\u001b[38;5;241m.\u001b[39mstartswith(proto\u001b[38;5;241m.\u001b[39mRETURN_MESSAGE):\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n", "\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}], "source": "results_new.count()"}, {"cell_type": "code", "execution_count": null, "id": "593c7564-3787-4035-85a0-782adc8b6285", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "25f3e91c-f678-44e8-a90d-3568932edf07", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "5d400e13-dadb-46b8-8da4-079b367b06d1", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 7, "id": "ad5d4c6a-bffa-4fa5-86eb-6bd0ffa2b76b", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/11/16 02:37:26 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1700094955838_0019_01_000001 on host: hub-msca-bdp-dphub-students-dheeraj-w-0.c.msca-bdp-student-ap.internal. Exit status: 137. Diagnostics: [2023-11-16 02:37:25.784]Container killed on request. Exit code is 137\n[2023-11-16 02:37:25.787]Container exited with a non-zero exit code 137. \n[2023-11-16 02:37:25.788]Killed by external signal\n.\n23/11/16 02:37:26 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 1 for reason Container from a bad node: container_1700094955838_0019_01_000001 on host: hub-msca-bdp-dphub-students-dheeraj-w-0.c.msca-bdp-student-ap.internal. Exit status: 137. Diagnostics: [2023-11-16 02:37:25.784]Container killed on request. Exit code is 137\n[2023-11-16 02:37:25.787]Container exited with a non-zero exit code 137. \n[2023-11-16 02:37:25.788]Killed by external signal\n.\n23/11/16 02:37:26 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 1 on hub-msca-bdp-dphub-students-dheeraj-w-0.c.msca-bdp-student-ap.internal: Container from a bad node: container_1700094955838_0019_01_000001 on host: hub-msca-bdp-dphub-students-dheeraj-w-0.c.msca-bdp-student-ap.internal. Exit status: 137. Diagnostics: [2023-11-16 02:37:25.784]Container killed on request. Exit code is 137\n[2023-11-16 02:37:25.787]Container exited with a non-zero exit code 137. \n[2023-11-16 02:37:25.788]Killed by external signal\n.\n23/11/16 02:37:26 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1.0 in stage 3.0 (TID 11) (hub-msca-bdp-dphub-students-dheeraj-w-0.c.msca-bdp-student-ap.internal executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container from a bad node: container_1700094955838_0019_01_000001 on host: hub-msca-bdp-dphub-students-dheeraj-w-0.c.msca-bdp-student-ap.internal. Exit status: 137. Diagnostics: [2023-11-16 02:37:25.784]Container killed on request. Exit code is 137\n[2023-11-16 02:37:25.787]Container exited with a non-zero exit code 137. \n[2023-11-16 02:37:25.788]Killed by external signal\n.\n[Stage 3:============================================>              (3 + 1) / 4]\r"}, {"ename": "KeyboardInterrupt", "evalue": "", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)", "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgs://msca-bdp-project-goodreads/reviews_summarized/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/readwriter.py:1250\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m-> 1250\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1303\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1296\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1305\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1033\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1033\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1200\u001b[0m, in \u001b[0;36mGatewayConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while sending\u001b[39m\u001b[38;5;124m\"\u001b[39m, e, proto\u001b[38;5;241m.\u001b[39mERROR_ON_SEND)\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1200\u001b[0m     answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   1201\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m answer\u001b[38;5;241m.\u001b[39mstartswith(proto\u001b[38;5;241m.\u001b[39mRETURN_MESSAGE):\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n", "\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}, {"name": "stderr", "output_type": "stream", "text": "23/11/16 02:41:51 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1700094955838_0019_01_000003 on host: hub-msca-bdp-dphub-students-dheeraj-w-1.c.msca-bdp-student-ap.internal. Exit status: 137. Diagnostics: [2023-11-16 02:41:51.083]Container killed on request. Exit code is 137\n[2023-11-16 02:41:51.084]Container exited with a non-zero exit code 137. \n[2023-11-16 02:41:51.085]Killed by external signal\n.\n23/11/16 02:41:51 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 3 for reason Container from a bad node: container_1700094955838_0019_01_000003 on host: hub-msca-bdp-dphub-students-dheeraj-w-1.c.msca-bdp-student-ap.internal. Exit status: 137. Diagnostics: [2023-11-16 02:41:51.083]Container killed on request. Exit code is 137\n[2023-11-16 02:41:51.084]Container exited with a non-zero exit code 137. \n[2023-11-16 02:41:51.085]Killed by external signal\n.\n23/11/16 02:41:51 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 3 on hub-msca-bdp-dphub-students-dheeraj-w-1.c.msca-bdp-student-ap.internal: Container from a bad node: container_1700094955838_0019_01_000003 on host: hub-msca-bdp-dphub-students-dheeraj-w-1.c.msca-bdp-student-ap.internal. Exit status: 137. Diagnostics: [2023-11-16 02:41:51.083]Container killed on request. Exit code is 137\n[2023-11-16 02:41:51.084]Container exited with a non-zero exit code 137. \n[2023-11-16 02:41:51.085]Killed by external signal\n.\n23/11/16 02:41:51 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1.1 in stage 3.0 (TID 14) (hub-msca-bdp-dphub-students-dheeraj-w-1.c.msca-bdp-student-ap.internal executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container from a bad node: container_1700094955838_0019_01_000003 on host: hub-msca-bdp-dphub-students-dheeraj-w-1.c.msca-bdp-student-ap.internal. Exit status: 137. Diagnostics: [2023-11-16 02:41:51.083]Container killed on request. Exit code is 137\n[2023-11-16 02:41:51.084]Container exited with a non-zero exit code 137. \n[2023-11-16 02:41:51.085]Killed by external signal\n.\n[Stage 3:============================================>              (3 + 1) / 4]\r"}], "source": "results.write.option('index',False).mode(\"overwrite\").parquet('gs://msca-bdp-project-goodreads/reviews_summarized/')"}, {"cell_type": "code", "execution_count": null, "id": "9ce21eff-1057-4aeb-8254-184aa5d650ac", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "f62a61e4-ac4f-48fe-9b9d-8106d3e0991c", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "markdown", "id": "dee75492-98a1-4b02-bd6e-4750cee6615f", "metadata": {}, "source": "### summary similarity"}, {"cell_type": "code", "execution_count": 7, "id": "1a20725b-859d-45a7-b876-9ca3b69ad3b4", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "tfhub_use_lg download started this may take some time.\nApproximate size to download 753.3 MB\n[ | ]tfhub_use_lg download started this may take some time.\nApproximate size to download 753.3 MB\n[ / ]Download done! Loading the resource.\n[ \\ ]"}, {"name": "stderr", "output_type": "stream", "text": "ERROR:root:Exception while sending command.\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1207, in send_command\n    raise Py4JNetworkError(\"Answer from Java side is empty\")\npy4j.protocol.Py4JNetworkError: Answer from Java side is empty\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1033, in send_command\n    response = connection.send_command(command)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1211, in send_command\n    raise Py4JNetworkError(\npy4j.protocol.Py4JNetworkError: Error while receiving\n"}, {"name": "stdout", "output_type": "stream", "text": "[OK!]"}, {"name": "stderr", "output_type": "stream", "text": "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\n"}, {"name": "stdout", "output_type": "stream", "text": "\n"}, {"name": "stderr", "output_type": "stream", "text": "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_5527/171762028.py\", line 8, in <module>\n    sentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py\", line 211, in pretrained\n    return ResourceDownloader.downloadModel(UniversalSentenceEncoder, name, lang, remote_loc)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py\", line 96, in downloadModel\n    j_obj = _internal._DownloadModel(reader.name, name, language, remote_loc, j_dwn).apply()\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py\", line 338, in __init__\n    super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 27, in __init__\n    self._java_obj = self.new_java_obj(java_obj, *args)\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py\", line 37, in new_java_obj\n    return self._new_java_obj(java_class, *args)\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 66, in _new_java_obj\n    return java_obj(*java_args)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n    return_value = get_return_value(\n  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 111, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 334, in get_return_value\n    raise Py4JError(\npy4j.protocol.Py4JError: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\n"}, {"ename": "Py4JError", "evalue": "An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)", "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m document_assembler \u001b[38;5;241m=\u001b[39m DocumentAssembler()\u001b[38;5;241m.\u001b[39msetInputCol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman_readable_summaries\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msetOutputCol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Separates the text into individual tokens (words and punctuation).\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#tokenizer = Tokenizer().setInputCols(['document']).setOutputCol('token')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Encodes the text as a single vector representing semantic features.\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m sentence_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mUniversalSentenceEncoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtfhub_use_lg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msetInputCols([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msetOutputCol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m nlp_pipeline \u001b[38;5;241m=\u001b[39m Pipeline(stages\u001b[38;5;241m=\u001b[39m[document_assembler, sentence_encoder])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Fit the model to an empty data frame so it can be used on inputs.\u001b[39;00m\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator/embeddings/universal_sentence_encoder.py:211\u001b[0m, in \u001b[0;36mUniversalSentenceEncoder.pretrained\u001b[0;34m(name, lang, remote_loc)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Downloads and loads a pretrained model.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    The restored model\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msparknlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpretrained\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResourceDownloader\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mResourceDownloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownloadModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mUniversalSentenceEncoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremote_loc\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained/resource_downloader.py:96\u001b[0m, in \u001b[0;36mResourceDownloader.downloadModel\u001b[0;34m(reader, name, language, remote_loc, j_dwn)\u001b[0m\n\u001b[1;32m     94\u001b[0m t1\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     j_obj \u001b[38;5;241m=\u001b[39m \u001b[43m_internal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_DownloadModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremote_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj_dwn\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mapply()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/__init__.py:338\u001b[0m, in \u001b[0;36m_DownloadModel.__init__\u001b[0;34m(self, reader, name, language, remote_loc, validator)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, reader, name, language, remote_loc, validator):\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_DownloadModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcom.johnsnowlabs.nlp.pretrained.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.downloadModel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremote_loc\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py:27\u001b[0m, in \u001b[0;36mExtendedJavaWrapper.__init__\u001b[0;34m(self, java_obj, *args)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28msuper\u001b[39m(ExtendedJavaWrapper, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(java_obj)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_java_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjava_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py:37\u001b[0m, in \u001b[0;36mExtendedJavaWrapper.new_java_obj\u001b[0;34m(self, java_class, *args)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_java_obj\u001b[39m(\u001b[38;5;28mself\u001b[39m, java_class, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_java_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjava_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/wrapper.py:66\u001b[0m, in \u001b[0;36mJavaWrapper._new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     64\u001b[0m     java_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(java_obj, name)\n\u001b[1;32m     65\u001b[0m java_args \u001b[38;5;241m=\u001b[39m [_py2java(sc, arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjava_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mjava_args\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n", "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel"]}], "source": "# Transforms the input text into a document usable by the SparkNLP pipeline.\ndocument_assembler = DocumentAssembler().setInputCol('human_readable_summaries').setOutputCol('document')\n\n# Separates the text into individual tokens (words and punctuation).\n#tokenizer = Tokenizer().setInputCols(['document']).setOutputCol('token')\n\n# Encodes the text as a single vector representing semantic features.\nsentence_encoder = UniversalSentenceEncoder.pretrained(name='tfhub_use_lg').setInputCols(['document']).setOutputCol('sentence_embeddings')\n\nnlp_pipeline = Pipeline(stages=[document_assembler, sentence_encoder])\n\n# Fit the model to an empty data frame so it can be used on inputs.\nempty_df = spark.createDataFrame([['']]).toDF('text')\npipeline_model = nlp_pipeline.fit(empty_df)\nlight_pipeline = LightPipeline(pipeline_model)"}, {"cell_type": "code", "execution_count": null, "id": "ee53267b-b8d7-4c8a-8515-9d4d381cd195", "metadata": {}, "outputs": [], "source": "phase"}, {"cell_type": "code", "execution_count": null, "id": "501ec8ca-5043-47f6-9cb0-f4f2ec9bfa7a", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "d815c082-db22-432b-8248-f02d78323168", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "markdown", "id": "0fb02d09-841f-476b-bd27-a859e4e38180", "metadata": {}, "source": "### EDA - REVIEWS WORD COUNT"}, {"cell_type": "code", "execution_count": 6, "id": "673a86c5-948d-4fe0-bbe0-4e72f836f50d", "metadata": {}, "outputs": [], "source": "reviews_df = reviews_df.select('book_id','review_text')\n\nreviews_df = reviews_df.withColumn(\"words\", F.split(reviews_df[\"review_text\"], \" \"))\n\n# Get the word count for each review\nreviews_df = reviews_df.withColumn(\"word_count\", F.size(reviews_df[\"words\"]))"}, {"cell_type": "code", "execution_count": 7, "id": "c99c0a23-fde4-41d5-a635-6fed11c603ca", "metadata": {}, "outputs": [], "source": "grouped_df = reviews_df.groupby('word_count').agg({\"book_id\": \"count\"})"}, {"cell_type": "code", "execution_count": 8, "id": "cd5897be-f615-4072-81f4-a733a3846b1d", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "grouped_df = grouped_df.toPandas()"}, {"cell_type": "code", "execution_count": 13, "id": "bc3ebd3a-5e28-4ea7-bda7-4cca67518773", "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_count</th>\n      <th>count(book_id)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>148</td>\n      <td>25666</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>496</td>\n      <td>3346</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>463</td>\n      <td>3884</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>471</td>\n      <td>3713</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>833</td>\n      <td>609</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   word_count  count(book_id)\n0         148           25666\n1         496            3346\n2         463            3884\n3         471            3713\n4         833             609"}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": "grouped_df.head()"}, {"cell_type": "code", "execution_count": 10, "id": "2cebc2f0-2313-49e9-b0f4-b9923947a722", "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_count</th>\n      <th>count(book_id)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3672.000000</td>\n      <td>3672.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1850.629902</td>\n      <td>4286.483388</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1085.115978</td>\n      <td>18615.957918</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>918.750000</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1836.500000</td>\n      <td>21.500000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2757.250000</td>\n      <td>431.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>6665.000000</td>\n      <td>247255.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "        word_count  count(book_id)\ncount  3672.000000     3672.000000\nmean   1850.629902     4286.483388\nstd    1085.115978    18615.957918\nmin       1.000000        1.000000\n25%     918.750000        4.000000\n50%    1836.500000       21.500000\n75%    2757.250000      431.500000\nmax    6665.000000   247255.000000"}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": "grouped_df.describe()"}, {"cell_type": "code", "execution_count": 27, "id": "db682c3d-1b7a-4930-8282-0938cfc38138", "metadata": {}, "outputs": [], "source": "grouped_df = grouped_df.sort_values(by=['word_count'])"}, {"cell_type": "code", "execution_count": 28, "id": "2ddda6e7-ad81-4b35-a360-b7a33dc7bdc2", "metadata": {}, "outputs": [], "source": "grouped_df[\"running_sum\"] = grouped_df[\"count(book_id)\"].cumsum()"}, {"cell_type": "code", "execution_count": 29, "id": "6a7cab76-bb22-41a9-806b-0b15d6bc10ba", "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_count</th>\n      <th>count(book_id)</th>\n      <th>running_sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>601</th>\n      <td>1</td>\n      <td>247255</td>\n      <td>247255</td>\n    </tr>\n    <tr>\n      <th>3184</th>\n      <td>2</td>\n      <td>212377</td>\n      <td>459632</td>\n    </tr>\n    <tr>\n      <th>944</th>\n      <td>3</td>\n      <td>205567</td>\n      <td>665199</td>\n    </tr>\n    <tr>\n      <th>1862</th>\n      <td>4</td>\n      <td>185312</td>\n      <td>850511</td>\n    </tr>\n    <tr>\n      <th>1049</th>\n      <td>5</td>\n      <td>184496</td>\n      <td>1035007</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1734</th>\n      <td>4999</td>\n      <td>1</td>\n      <td>15739963</td>\n    </tr>\n    <tr>\n      <th>3158</th>\n      <td>5202</td>\n      <td>1</td>\n      <td>15739964</td>\n    </tr>\n    <tr>\n      <th>2273</th>\n      <td>5443</td>\n      <td>1</td>\n      <td>15739965</td>\n    </tr>\n    <tr>\n      <th>3141</th>\n      <td>5454</td>\n      <td>1</td>\n      <td>15739966</td>\n    </tr>\n    <tr>\n      <th>1225</th>\n      <td>6665</td>\n      <td>1</td>\n      <td>15739967</td>\n    </tr>\n  </tbody>\n</table>\n<p>3672 rows \u00d7 3 columns</p>\n</div>", "text/plain": "      word_count  count(book_id)  running_sum\n601            1          247255       247255\n3184           2          212377       459632\n944            3          205567       665199\n1862           4          185312       850511\n1049           5          184496      1035007\n...          ...             ...          ...\n1734        4999               1     15739963\n3158        5202               1     15739964\n2273        5443               1     15739965\n3141        5454               1     15739966\n1225        6665               1     15739967\n\n[3672 rows x 3 columns]"}, "execution_count": 29, "metadata": {}, "output_type": "execute_result"}], "source": "grouped_df"}, {"cell_type": "code", "execution_count": 32, "id": "2632c716-f75d-4213-8a3d-5dc124552697", "metadata": {}, "outputs": [{"data": {"text/plain": "2657619"}, "execution_count": 32, "metadata": {}, "output_type": "execute_result"}], "source": "grouped_df[grouped_df['word_count']<15]['count(book_id)'].sum()"}, {"cell_type": "code", "execution_count": 31, "id": "3204e9b9-5afb-4ec1-86b2-39a275157543", "metadata": {}, "outputs": [{"data": {"image/png": "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", "text/plain": "<Figure size 1000x600 with 1 Axes>"}, "metadata": {}, "output_type": "display_data"}], "source": "import matplotlib.pyplot as plt\nplt.figure(figsize=(10, 6))\nplt.bar(grouped_df[\"word_count\"], grouped_df[\"running_sum\"])\nplt.xlabel(\"Number of Words\")\nplt.ylabel(\"Number of Books\")\nplt.title(\"Number of Words vs Number of Books\")\nplt.show()"}, {"cell_type": "code", "execution_count": null, "id": "66119de2-9c78-4f5e-8089-84aa8ac9e4af", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}